name: Daily Hive Report

on:
  schedule:
    # Every day at UTC 03:00
    - cron: "0 3 * * 1,2,3,4,5"
  workflow_dispatch:
  pull_request:
    paths:
      - .github/workflows/daily_hive_report.yaml
      - .github/scripts/publish_hive.sh

permissions:
  contents: read
  actions: write

jobs:
  run-hive:
    name: Hive - ${{ matrix.test.name }}
    runs-on: ubuntu-latest
    continue-on-error: true
    strategy:
      fail-fast: false
      matrix:
        test:
          - {
              name: "Rpc Compat tests",
              file_name: rpc-compat,
              simulation: ethereum/rpc-compat,
              limit: "",
            }
          - {
              name: "Devp2p eth tests",
              file_name: devp2p,
              simulation: devp2p,
              limit: "",
            }
          - {
              name: "Engine tests",
              file_name: engine,
              simulation: ethereum/engine,
              limit: "",
            }
          - {
              name: "Sync tests",
              file_name: sync,
              simulation: ethereum/sync,
              limit: "",
            }
          - {
              name: "Consume Engine tests (Rest)",
              file_name: consume-engine-rest,
              simulation: ethereum/eels/consume-engine,
              limit: ".*fork_Paris.*|.*fork_Shanghai.*|.*fork_Cancun.*",
            }
          - {
              name: "Consume Engine tests (Prague)",
              file_name: consume-engine-prague,
              simulation: ethereum/eels/consume-engine,
              limit: ".*fork_Prague.*",
            }
          - {
              name: "Consume Engine tests (Osaka)",
              file_name: consume-engine-osaka,
              simulation: ethereum/eels/consume-engine,
              limit: ".*fork_Osaka.*",
            }
          - {
              name: "Consume RLP tests (Rest)",
              file_name: consume-rlp-rest,
              simulation: ethereum/eels/consume-rlp,
              limit: ".*fork_Paris.*|.*fork_Shanghai.*|.*fork_Cancun.*",
            }
          - {
              name: "Consume RLP tests (Prague)",
              file_name: consume-rlp-prague,
              simulation: ethereum/eels/consume-rlp,
              limit: ".*fork_Prague.*",
            }
          - {
              name: "Consume RLP tests (Osaka)",
              file_name: consume-rlp-osaka,
              simulation: ethereum/eels/consume-rlp,
              limit: ".*fork_Osaka.*",
            }
          - {
              name: "Execute Blobs tests",
              file_name: execute-blobs,
              simulation: ethereum/eels/execute-blobs,
              limit: "",
            }

    steps:
      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@v1.3.1
        with:
          tool-cache: false
          large-packages: false

      - name: Checkout sources
        uses: actions/checkout@v4

      # Set custom args defined in Dockerfile to pin execution-spec-tests versions
      # See: https://github.com/ethereum/hive/blob/c2dab60f898b94afe8eeac505f60dcde59205e77/simulators/ethereum/eest/consume-rlp/Dockerfile#L4-L8
      - name: Determine hive flags
        id: hive-flags
        shell: bash
        env:
          SIMULATION: ${{ matrix.test.simulation }}
          SIM_LIMIT: ${{ matrix.test.limit || '' }}
        run: |
          FLAGS='--sim.parallelism 4 --sim.loglevel 1'
          if [[ "$SIMULATION" == "ethereum/eels/consume-engine" || "$SIMULATION" == "ethereum/eels/consume-rlp" ]]; then
            FLAGS+=" --sim.buildarg fixtures=https://github.com/ethereum/execution-spec-tests/releases/download/v5.3.0/fixtures_develop.tar.gz"
            FLAGS+=" --sim.buildarg branch=forks/osaka"
            FLAGS+=" --client.checktimelimit=180s"
          fi
          if [[ -n "$SIM_LIMIT" ]]; then
            FLAGS+=" --sim.limit \"$SIM_LIMIT\""
          fi
          echo "flags=$FLAGS" >> "$GITHUB_OUTPUT"

      - name: Run Hive Simulation
        id: run-hive-action
        uses: ethpandaops/hive-github-action@v0.5.0
        continue-on-error: true
        with:
          simulator: ${{ matrix.test.simulation }}
          client: ethrex
          extra_flags: ${{ steps.hive-flags.outputs.flags }}
          workflow_artifact_upload: true
          workflow_artifact_prefix: ${{ matrix.test.file_name }}_daily

  hive-report:
    name: Generate and Save report
    needs: run-hive
    if: ${{ always() }}
    runs-on: ubuntu-latest
    outputs:
      artifact_name: results_daily.md
    steps:
      - name: Checkout sources
        uses: actions/checkout@v4
      - name: Setup Rust Environment
        uses: ./.github/actions/setup-rust

      - name: Download all results
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          path: hive/workspace/logs
          pattern: "*_daily-results.zip"
          merge-multiple: true

      - name: Flatten hive result files
        shell: bash
        run: |
          shopt -s globstar nullglob
          mkdir -p hive/workspace/logs
          for json in hive/workspace/logs/**/*.json; do
            base_name=$(basename "$json")
            target="hive/workspace/logs/$base_name"
            if [[ "$json" != "$target" ]]; then
              mv "$json" "$target"
            fi
          done
          find hive/workspace/logs -mindepth 1 -type d -exec rm -rf {} +

      - name: Print failed tests
        if: always()
        shell: bash
        run: |
          shopt -s nullglob
          found_failures=false
          for log in hive/workspace/logs/*.log; do
            mapfile -t failures < <(grep 'FAILED ' "$log" | sed -E 's/^.*FAILED ([^ ]+).*/\1/' || true)
            if (( ${#failures[@]} )); then
              found_failures=true
              echo "Failures in $(basename "$log"):"
              printf '  %s\n' "${failures[@]}"
              echo
            fi
          done
          if [ "$found_failures" = false ]; then
            echo "No test failures found in logs."
          fi

      - name: Generate the hive report
        run: cargo run --manifest-path tooling/Cargo.toml -p hive_report > results.md

      - name: Upload daily result
        uses: actions/upload-artifact@v4
        with:
          name: results_daily.md
          path: results.md
          if-no-files-found: error

      - name: Post results in summary
        run: |
          echo "# Hive coverage report" >> $GITHUB_STEP_SUMMARY
          cat results.md >> $GITHUB_STEP_SUMMARY

  post-daily-report:
    name: Post report to slack
    needs: [hive-report]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout sources
        uses: actions/checkout@v4

      - name: Download hive results
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.hive-report.outputs.artifact_name }}

      - name: Post Hive results to Slack
        env:
          SLACK_WEBHOOKS: >
            ${{ github.event_name == 'schedule'
              && format(
                  '{0} {1}',
                  secrets.ETHREX_L1_SLACK_WEBHOOK,
                  secrets.ETHREX_L2_SLACK_WEBHOOK
                )
              || secrets.TEST_CHANNEL_SLACK
            }}
        run: |
          for webhook in $SLACK_WEBHOOKS; do
            sh .github/scripts/publish_hive.sh "$webhook" results.md
          done
          echo "Sending Results" >> $GITHUB_STEP_SUMMARY
